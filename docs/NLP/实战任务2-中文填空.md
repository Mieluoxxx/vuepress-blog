---
title: 实战任务2：中文填空
---
## 实战任务：中文填空

### 任务简介

人类在阅读一个句子时，即使挖掉句子中的一两个词，往往也能根据上下文猜出被挖掉的是什么词，这被称作填空任务，例如如下是一道典型的填空题：
“外观很漂亮，特别____ 合女孩子使用。”

人类很容易就能猜出横线处应该填写“适”字，这样才能符合上下文的语义，而人类是通过从小到大每天的听、说、读、写交流获得这样的普遍性知识的。自然语言虽然复杂，但却有着明显的统计规律，而神经网络最擅长的就是找出统计规律，所以本章将尝试使用预训练神经网络完成填空任务。



### 数据集介绍

在数据处理的过程中，会把每句话的第15个词挖掉，也就是替换成特殊符号[MASK]，并且每句话会被截断成固定的30个词的长度，神经网络的任务就是根据每句话的上下文，把第15个词预测出来。
![1700915300552.png](http://pic.moguw.top/i/2023/11/25/6561e865d104c.png)



### 模型架构

在本次任务中，依然将一个预训练的BERT模型当作backbone网络层使用，使用该backbone来抽取文本数据特征，后续接入下游任务模型来把抽取的数据特征还原为任务需要的答案。由于填空任务的答案可能是词表中的任何一个词，所以这可以视为一个多分类任务，分类的数目为整个词表的词数量。

首先把文本数据输入backbone网络抽取数据特征，再把数据特征输入下游任务模型进行计算，下游任务模型将把数据特征投影到全体词表空间，即可得出最终的预测词。
![1700915398661.png](http://pic.moguw.top/i/2023/11/25/6561e8c7c5ac0.png)
在本次任务中，将忽略对backbone的训练，只是将backbone当作一个数据特征抽取层使用。在训练过程中，只训练下游任务模型，这将节约宝贵的计算资源，但会降低预测正确率。如果读者对预测正确率有较高要求，则可以连同backbone共同参与训练，能有效地提高预测正确率，但需要更多的训练时间和训练数据。



### 准备数据集
1. 使用编码工具
首先需要加载编码工具，编码工具能够把抽象的文字转换成数字，便于神经网络的后续处理
```python
from transformers import BertTokenizer 
token = BertTokenizer.from_pretrained('bert-base-chinese') 
token
```
加载编码工具之后，不妨进行一次试算，以便更清晰地观察编码工具的输入和输出，代码如下：
```python
# 试编码句子 
out = token.batch_encode_plus( 
			batch_text_or_text_pairs=['轻轻地我走了，正如我轻轻地来。', '我轻轻地招手，作 别西天的云彩。'], 
			truncation=True, 
			padding='max_length', 
			max_length=18, 
			return_tensors='pt', 
			return_length=True) 
# 查看编码输出 
for k, v in out.items(): 
	print(k, v.shape) 
	# 把编码还原为句子 
	print(token.decode(out['input_ids'][0]))
```

2. 定义数据集
在本次任务中，依然将使用ChnSentiCorp数据集，但需要对数据集进行一些操作，将它变成一个填空任务数据集。在开始处理之前，首先需要加载数据集，代码如下：
```python
# 加载数据集 
from datasets import load_dataset
dataset = load_dataset(path='lansinuote/ChnSentiCorp')
dataset
```
有了文本数据之后，接下来需要对这些文本数据进行编码，便于后续的处理
```python
# 编码数据，同时删除多余的字段
def f(data):
	return token.batch_encode_plus(
					batch_text_or_text_pairs=data['text'],
					truncation=True,
					padding='max_length',
					max_length=30,
					return_length=True)
					
dataset = dataset.map(
	function=f,
	batched=True,
	batch_size=1000,
	num_proc=4,
	remove_columns=['text', 'label'])
	
dataset
```
在这段代码中，使用了之前加载的编码工具，对数据集中的text字段进行了编码，编码的结果同之前编码器的试算结果一致。
(1)参数`truncation=True`和`max_length=30`意味着编码结果的长度不会长于30个词，超出30个词的部分会被截断。
(2)参数`padding='max_length'`表明不足30个词的句子会被补充PAD，直到达到30个词的长度。
(3)参数`return_length=True`会让编码结果中多出一个length字段，表明这段数据的长度，由于PAD不会被计算在长度内，所以length一定小于或等于30，这个字段方便了后续的数据过滤。
在数据集上调用`map()`函数时使用了批处理加速，每1000条数据为一个批次调用一次编码函数，关于数据集的批处理加速在“数据集”一章已经详细介绍，如果读者对此感到困惑，则可以参考“数据集”一章。调用`map()`函数时还指定了参数`remove_columns=['text','label']`：表示丢弃原数据中的text和label数据，只需编码的结果。
```python
DatasetDict({ 
	train: Dataset({ 
			features: ['input_ids', 'token_type_ids', 'length', 'attention_mask'], 
			num_rows: 9600 }) 
	validation: Dataset({ 
			features: [], num_rows: 0 }) 
	test: Dataset({ 
			features: ['input_ids', 'token_type_ids', 'length', 'attention_mask'], 
			num_rows: 1200 }) 
})
```

在编码的过程中，把所有长于30个词的句子都截断了，现在所有的句子的长度都小于或等于30个词了。接下来要把所有小于30个词的句子丢弃，确保所有输入模型训练的句子都刚好30个词，由于在编码过程中让编码器返回了每句话的长度，所以很容易完成这个过滤，
```python
# 过滤掉太短的句子 
def f(data): 
	return [i >= 30 for i in data['length']] 
dataset = dataset.filter(function=f, batched=True, batch_size=1000, num_proc=4) 
dataset
```
可以看到在训练集中少了314条数据，在测试集中少了43条，这个数据损失的量在可接受的范围内。以此为代价，现在所有数据的长度都是30个词了，这方便了后续的数据处理工作。

3. 定义计算设备
```python
# 定义计算设备 
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

4. 定义数据整理函数
本次的任务为填空任务，现在的数据中每句话都是由30个词组成的，所以可以把每句话的第15个词挖出作为label，也就是网络模型预测的目标，为了防止网络直接从原句子中读取答案，把每句话的第15个词替换为[MASK]。相当于在需要网络模型填答案的位置画横线，同时擦除正确答案。网络模型需要根据[MASK]的上下文把[MASK]处原本的词预测出来。

上述工作将在数据整理函数中完成，数据整理函数还有把多条数据合并为一个批次的功能。使用批量数据训练不仅能提高数据处理的速度，节约训练、测试的时间，还能让loss的梯度更平稳，让模型参数更稳定地更新。

```python
# 数据整理函数 
def collate_fn(data): 
	# 取出编码结果 
	input_ids = [i['input_ids'] for i in data] 
	attention_mask = [i['attention_mask'] for i in data] 
	token_type_ids = [i['token_type_ids'] for i in data] 
	# 转换为Tensor格式 
	input_ids = torch.LongTensor(input_ids) 
	attention_mask = torch.LongTensor(attention_mask) 
	token_type_ids = torch.LongTensor(token_type_ids) 
	# 把第15个词替换为MASK 
	labels = input_ids[:, 15].reshape(-1).clone() 
	input_ids[:, 15] = token.get_vocab()[token.mask_token] 
	# 移动到计算设备 
	input_ids = input_ids.to(device) 
	attention_mask = attention_mask.to(device) 
	token_type_ids = token_type_ids.to(device) 
	labels = labels.to(device) 
	return input_ids, attention_mask, token_type_ids, labels
```
在这段代码中，入参的data表示一批数据，其中的内容为编码工具编码的结果。

接下来把3个矩阵移动到之前定义好的计算设备上，方便后续的模型计算。定义好了数据整理函数，不妨假定一批数据，让数据整理函数进行试算，以观察数据整理函数的输入和输出
```python
# 数据整理函数试算 
# 模拟一批数据 
data = [{ 
		 'input_ids': [ 101, 2769, 3221, 3791, 6427, 1159, 2110, 5442, 117, 2110, 749, 8409, 702, 6440, 3198, 4638, 1159, 5277, 4408, 119, 1728, 711, 2769, 3221, 5439, 2399, 782, 117, 3791, 102 ], 
		 'token_type_ids': [0] * 30, 
		 'attention_mask': [1] * 30 }, 
		 { 'input_ids': [ 101, 679, 7231, 8024, 2376, 3301, 1351, 6848, 4638, 8024, 3301, 1351, 3683, 6772, 4007, 2692, 8024, 2218, 3221, 100, 2970, 1366, 2208, 749, 8024, 5445, 684, 1059, 3221, 102 ], 
		 'token_type_ids': [0] * 30, 
		 'attention_mask': [1] * 30 }] 
# 试算 
input_ids, attention_mask, token_type_ids, labels = collate_fn(data) 

# 把编码还原为句子 
print(token.decode(input_ids[0])) 
print(token.decode(labels[0])) 
input_ids.shape, attention_mask.shape, token_type_ids.shape, labels
```
在这段代码中先虚拟了一批数据，这批数据中包括两个句子，输入数据整理函数后，运行结果如下：
```python
[CLS] 我　是 法　语 初　学 者，学　了 78 个　课 时 [MASK] 初　级 班. 因　为 我　是 老　年 人， 法 [SEP] 的 (torch.Size([2, 30]), torch.Size([2, 30]), torch.Size([2, 30]), tensor([4638, 2692], device='CUDA:0'))
```
可以看到第一句话的[MASK]处应该填写“的”字，这也比较符合自然语义。此外可以看到编码之后的结果都是确定的30个词，并且每个结果都被移动到了可用的计算设备上，这方便了后续的计算。

5. 数据加载器
```python
# 定义数据集加载器
loader = torch.utils.data.DataLoader(
	dataset=dataset['train'],
	batch_size=16,
	collate_fn=collate_fn,
	shuffle=True, drop_last=True)
len(loader)
```

6. 定义好了数据集加载器之后，可以查看一批数据样例
```python
# 查看数据样例 
for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader): 
	break 
print(token.decode(input_ids[0])) 
print(token.decode(labels[0])) 
input_ids.shape, attention_mask.shape, token_type_ids.shape, labels
```
这段代码把一批数据中的第1条还原为了文本形式，便于人类观察，可以看到这段文本的[MASK]处应该填写“的”字，这比较符合自然语义。



### 定义模型

1.加载预训练模型
```python
# 加载预训练模型 
from transformers import BertModel 
pretrained = BertModel.from_pretrained('bert-base-chinese') # 统计参数量 
sum(i.numel() for i in pretrained.parameters()) / 10000
```
可见bert-base-chinese模型的参数量约为1亿个，在本次任务中选择不训练它

```python
# 不训练预训练模型，不需要计算梯度 
for param in pretrained.parameters(): 
	param.requires_grad_(False)
```

定义好预训练模型之后，可以进行一次试算
```python
# 预训练模型试算 
pretrained.to(device) # 模型试算 
out = pretrained(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids) 
out.last_hidden_state.shape
```
此处输入的数据就是之前看到的样例数据，从预训练模型的计算结果可以看出，这也是16句话的结果，每句话包括30个词，每个词被抽成了一个768维的向量。

2. 定义下游任务模型
完成以上工作后，现在可以定义下游任务模型了，下游任务模型的任务是对backbone抽取的特征进行下一步计算，得到符合业务需求的计算结果，对于本章的任务来讲，需要计算一个多分类的结果，类别的数目等于整个词表的词数量，模型理想的计算结果为数据集中的label字段，代码如下：

```python
class Model(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.decoder = torch.nn.Linear(
            in_features=768, 
            out_features=token.vocab_size, 
            bias = False)
        # 重新将decode中的bias参数设置为全0
        self.bias = torch.nn.Parameter(data=torch.zeros(token.vocab_size))
        self.decoder.bias = self.bias
        # 定义Dropout层，防止过拟合
        self.Dropout = torch.nn.Dropout(p=0.5)

    def forward(self, input_ids, attention_mask, token_type_ids):
        # 预训练模型抽取数据特征
        with torch.no_grad():
            out = pretrained(input_ids=input_ids,
                             attention_mask=attention_mask,
                             token_type_ids=token_type_ids)
        # 把第十五个词的特征投影到全字典范围内
        out = self.Dropout(out.last_hidden_state[:,15])
        out = self.decoder(out)
        return out

model = Model()
model.to(device)
```

在这段代码中，定义了下游任务模型，该模型只包括一个全连接的线性神经网络，权重矩阵为768×21128，所以它能够把一个768维度的向量转换到21128维空间中。21128这个数字来自编码器的字典空间，它是编码器所认识的字的数量，所以可以理解为下游任务模型可以把backbone抽取的数据特征还原为字典中的任何一个字。

下游任务模型的计算过程为，获取一批数据之后，使用backbone将这批数据抽取成特征矩阵，抽取的特征矩阵的形状应该是16×30×768，这在之前预训练模型的试算中已经看到。这3个维度分别代表了16句话、30个词、768维度的特征向量。

在本次的填空任务中，填空处固定出现在每句话的第15个词的位置，所以只取出每句话的第15个词的特征，再尝试把这个词的特征投影到全体词表空间中，即还原为词典中的某个词。

在投影到全体词表空间中时，由于768×21128是一个很大的矩阵，如果直接计算，则很容易导致过拟合，所以对backbone抽取的数据特征要接入一个DropOut网络，把其中的数据以一定的概率置为0，防止网络的过拟合。



如果在该结果上再套用Softmax()函数，则为在全体词表中每个词的概率。

::warning

在此处的计算后不建议再套用Softmax作为激活函数，因为分类的结果比较多，导致每个类别分到的概率都非常低，套用Softmax后大多数类别的概率将非常接近0，这在计算参数梯度时会出现问题，也就是出现了梯度消失的情况，这不利于模型的训练和收敛，所以不建议在计算过程中套用Softmax。

::

### 训练

```python
from transformers import AdamW
from transformers.optimization import get_scheduler

def train():
    # 定义优化器
    optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=1.0)
    # 定义loss函数
    criterion = torch.nn.CrossEntropyLoss()
    # 定义学习率调节器
    scheduler = get_scheduler(name='linear',
                              num_warmup_steps=0,
                              num_training_steps=len(loader)*5,
                              optimizer=optimizer)
    # 将模型切换到训练模式
    model.train()
    # 共训练5个epoch
    for epoch in range(5):
        for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):
            # 模型计算
            out = model(input_ids=input_ids, 
                        attention_mask=attention_mask, 
                        token_type_ids=token_type_ids)
            # 计算loss并使用梯度下降法优化模型参数
            loss = criterion(out, labels)
            loss.backward()
            optimizer.step()
            scheduler.step()
            optimizer.zero_grad()
            
            # 输出各项数据的情况便于观察
            if i % 50 == 0:
                out = out.argmax(dim=1)
                accuracy = (out==labels).sum().item() / len(labels)
                lr = optimizer.state_dict()['param_groups'][0]['lr']
                print(epoch, i, loss.item(), lr, accuracy)
train()
```



### 测试

```python
def test():
    # 定义测试数据集加载器
    loader_test = torch.utils.data.DataLoader(dataset=dataset[test],
                                              batch_size=32,
                                              collate_fn=collate_fn,
                                              shuffle=True,
                                              drop_last=True)
    # 将下游任务模型切换到运行模式
    model.eval()
    correct = 0
    total = 0
    # 按批次遍历测试集中的数据
    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):
        # 计算15个批次即可
        if i == 15:
            break
        print(i)
        # 计算
        with torch.no_grad():
            out = model(input_ids=input_ids,
                        attention_mask=attention_mask,
                        token_type_ids=token_type_ids)
        
        # 统计正确率
        out = out.argmax(dim=1)
        correct += (out==labels).sum().item()
        total += len(labels)
    print(correct/total)
test()
```

本章通过一个填空的例子讲解了使用BERT预训练模型抽取文本特征数据的方法，事实上填空任务也是BERT模型本身在训练时的一个子任务，所以使用BERT模型在做填空任务时效果往往较好，在处理不同的任务时，应该选择合适的预训练模型。

填空任务本身可以被视为一个多分类任务，但由于全体词表空间的数量比较大，往往有上万个词，所以是个类别特别多的多分类任务，这导致在输出时很容易过拟合，本章演示了使用DropOut层来随机断开部分网络权重和使用权重参数衰减这两种方式来缓解过拟合。

分类的类别太多也容易出现梯度消失的问题，所以在下游任务的输出时不能使用Softmax函数激活，需要格外注意。
